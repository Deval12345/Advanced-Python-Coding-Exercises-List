In the previous lecture, we saw how data descriptors implement reusable attribute validation by intercepting writes through __set__. A data descriptor always wins over the instance's __dict__, which means every read and every write to the attribute goes through the descriptor's methods. Now we look at the other side: non-data descriptors and the patterns they enable. A non-data descriptor defines only __get__ — no __set__. The instance's __dict__ takes priority over it. This priority reversal is not a limitation. It is the exact mechanism that makes lazy loading possible.

Let us start with the problem that lazy loading solves. Some object attributes are expensive to compute. Parsing a 10-megabyte configuration file. Executing a database join across three tables. Loading a machine learning model by reading 500 megabytes of weights and parsing them into a numerical format. Computing a graph traversal over a million nodes. If you compute these in __init__, you pay the full cost every time an instance is created — even in execution paths that never access the expensive attribute. If you compute them inside a property on every access, you repeat the full work on every single read. For a word count that reads a large document, that is redundant I/O on every call. For a model loader, it is a prohibitive amount of repeated work.

Lazy loading is the solution: compute the value exactly once, the first time it is accessed, cache it, and return the cached value on all subsequent accesses. The interface to the caller never changes. From the caller's perspective it looks like a plain attribute access — no method calls, no explicit cache checks, no separate initialization step. The caching is invisible and structural. Descriptors make this possible without any modification to the calling code.

Here is how it works mechanically. A non-data descriptor defines only __get__. Python's attribute lookup checks in this order: data descriptors first, then instance __dict__, then non-data descriptors. On the first access, the instance __dict__ has no entry for the attribute, so Python reaches the non-data descriptor and calls __get__. Inside __get__, we compute the expensive value, then we do this: we write the result directly into instance.__dict__ under the attribute name. Then we return the value. On the second access, Python checks instance.__dict__ first, finds the cached result, and returns it immediately. __get__ is never called again. The descriptor computed the value once and then permanently stepped out of the way. No flags, no if-already-computed guards, no separate cache dictionary. The lookup priority mechanism handles everything.

The first example shows a LazyProperty descriptor class. The constructor takes the function to call when the attribute is first needed. __set_name__ stores the attribute name at class creation time. __get__ computes the value by calling computeFunction(instance), stores the result in instance.__dict__[self.attributeName], and returns it. We apply it with the @LazyProperty decorator on the processedData method of ReportData. When we first access report.processedData, the print message appears and the processing runs. When we access it a second time, the print message does not appear — the cached list is returned directly from the instance dictionary. The function body ran exactly once, no matter how many times the attribute is accessed afterward.

Now consider the choice between a computed property and a cached property. Not every derived value should be cached. A Rectangle's area is width times height. If the width changes, the cached area is wrong. For mutable-state-derived values, you want a computed property: recalculate every time, always fresh. Python's built-in property is a data descriptor that calls your getter function on every access. It is the right tool for values that must always reflect current state.

For values derived from state that does not change after creation — a parsed document's word count, a loaded dataset's feature statistics, a compiled regular expression — you want a cached property: compute once, return forever. Python 3.8 introduced functools.cached_property in the standard library. It implements exactly the LazyProperty pattern we just built: a non-data descriptor whose __get__ writes the result into instance.__dict__. You can now understand precisely why cached_property works and why it was specifically designed as a non-data descriptor. The second example demonstrates both patterns side by side. recordCount uses @property and reflects live changes to sourceData. summary uses @functools.cached_property and prints its computation message only once, no matter how many times you access it.

The third pattern is the one that makes major frameworks possible: descriptors as class-level APIs. When you access MyModel.id on a SQLAlchemy model through the class, you get back a column expression object. You use it in filter conditions: session.query(MyModel).filter(MyModel.id == 5). When you access instance.id on a model instance, you get the actual stored integer value. The same dot-access syntax produces completely different behavior depending on whether you go through the class or through an instance. This is the instance-is-None check in __get__: return self when instance is None, return the actual data when instance is an object. Django model fields work this way. dataclasses field objects work this way. The descriptor protocol is the only reason all of these APIs are possible.

The third example shows TypedField, an ORM-style descriptor with type enforcement and a default value. __get__ returns self when accessed through the class — giving frameworks access to the field's configuration — and returns the stored value when accessed through an instance. __set__ enforces the field type. The User class uses TypedField for name, age, and score. A valid user is created and printed. The example also shows that accessing User.name through the class returns the TypedField descriptor object itself, with its fieldType and default visible to any framework-level code that inspects it.

The fourth concept to understand is the complete lookup priority chain. When you write instance.attribute, Python performs four steps in order. First, it searches the class and its MRO for a data descriptor. If one is found, it calls that descriptor's __get__ and stops. Second, it checks instance.__dict__ for the attribute name. If found, it returns the value and stops. Third, it searches the class and MRO for a non-data descriptor. If found, it calls __get__ and stops. Fourth, if nothing matched, it calls __getattr__ if the class defines it, or raises AttributeError.

This chain explains every surprising attribute behavior in Python. property always wins over a same-named instance dictionary entry because property is a data descriptor. cached_property loses on the second access because it is a non-data descriptor and the instance dictionary now has the cached value, which takes priority. Functions defined in a class are non-data descriptors — that is how method binding works. When you call instance.method(), Python finds the function in the class as a non-data descriptor, calls its __get__, and receives a bound method object with the instance pre-filled as the first argument.

To put the two lectures together: data descriptors win over instance __dict__ and are the right tool for validation, where every write must pass through the descriptor. Non-data descriptors lose to instance __dict__ and are the right tool for lazy caching, where the first computation writes into __dict__ and later accesses hit __dict__ directly. The complete lookup priority chain — data descriptors, instance __dict__, non-data descriptors — explains the entire Python attribute model. Descriptors are not an advanced feature reserved for framework authors. They are the foundation of Python's object system, and understanding them gives you a complete mental model of how Python works.
