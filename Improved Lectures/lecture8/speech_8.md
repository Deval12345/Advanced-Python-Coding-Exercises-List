In our previous lecture, we studied closures — functions that remember the environment in which they were created. We saw how a function could carry captured state with it long after the outer scope that created it had finished executing. Today we return to the Python data model, and we go much deeper than we have before. We already saw that for loops and the dunder iter method are connected. But we never asked the deeper question — what exactly is an iterator, how is it different from an iterable, and why does that distinction matter so profoundly? Today we answer those questions with precision.

Let us begin at the foundation. When you write a for loop in Python, you might imagine that Python simply moves through a collection one item at a time. But that mental model is incomplete. Python executes a precise two-phase protocol every single time a for loop runs. When Python encounters a for loop, it does not begin moving through the collection immediately. It first calls dunder iter on the collection. That call returns a completely separate object — an iterator. Then Python calls dunder next on that iterator again and again until dunder next raises a StopIteration exception. When that exception is raised, the loop ends cleanly.

The collection and the iterator are potentially two entirely different objects. This is the key architectural insight. Python deliberately separates the thing you iterate over from the object that actually tracks where you are in the iteration. Why design it this way? Imagine you want to run two separate for loops over the same list at the same time — perhaps in a nested loop comparing every pair of elements. Each loop needs its own independent progress counter. If the list itself tracked the current position, two nested loops would collide and corrupt each other's state. By returning a fresh, independent iterator object each time dunder iter is called, Python makes this safe, clean, and predictable.

An iterable is any object that implements dunder iter and returns a new, independent iterator each time dunder iter is called. Lists are iterables. Tuples are iterables. Strings are iterables. When you call iter on a list, Python returns a list iterator object — a separate, lightweight object whose only job is to track the current position in that list. The list itself has no idea where you are in the iteration. Only the iterator does. This design gives you something powerful — an iterable is reusable. You can call iter on a list one hundred times and get one hundred independent iterators, each starting from the beginning, each independent of the others.

An iterator is a different kind of object. An iterator implements two methods: dunder iter and dunder next. The dunder next method is the core. Each call to dunder next returns the next value in the sequence. When there are no more values, dunder next raises StopIteration. That exception is not an error — it is a signal. It is the normal, expected way an iterator communicates that it is finished. The dunder iter method on an iterator is deliberately simple: it returns self. An iterator is its own iterator.

The critical consequence of this design is that iterators are single-use. Once dunder next has raised StopIteration, the iterator is exhausted. Calling dunder next again should continue raising StopIteration. The iterator cannot reset itself. It represents exactly one complete pass through a sequence of values.

This single-use nature is not a flaw. It is a deliberate design choice that enables Python to process data that is far too large to hold in memory. Before Python 2.2, you had to load all data into memory before iterating. The introduction of the iterator protocol in Python 2.2 changed everything. Python could now stream data from files, networks, and databases without loading it all first. Consider iterating over a file that is ten gigabytes. You cannot load ten gigabytes into a list. But you can read it one line at a time. The file object acts as an iterator — each call to dunder next reads and returns the next line. When the file ends, StopIteration is raised. The entire file was processed without ever holding more than one line in memory. This same design powers range. When you write range of one million, Python does not create a list of one million numbers. It creates a small object that knows its start, stop, and step. Each call to dunder next computes the next number on the fly. The memory usage is essentially zero regardless of the range size.

Now we come to one of the most important and most dangerous patterns in Python. This is a bug that produces no error message, no traceback, no warning of any kind. Data simply disappears. Here is the scenario. You build a class to represent a collection of data — let us say a TransactionBatch. You give it an init method that stores transaction data. You give it a dunder iter method. But inside dunder iter, instead of returning a fresh iterator over your data, you store an iterator as an instance variable and return self. What have you done? You have made your TransactionBatch an iterator, not an iterable. It has internal state that tracks position. The first time someone iterates over it, everything works. But the iterator is now exhausted. The second time someone iterates over it, they see nothing. No error. No exception. Just an empty sequence.

In a financial system, this is catastrophic. Imagine a batch of ten thousand transactions. The first consumer iterates through all of them to compute totals. The totals look correct. Then the second consumer iterates through the same batch to generate a report. The report is empty. The second consumer has no idea why. The batch object looks perfectly normal. No exception was raised. The data simply did not appear. This is the silent bug. It happens precisely when an iterable returns itself from dunder iter — making it an iterator that exhausts on the first pass.

The fix is always the same. Store the raw data as a list or other collection. In your dunder iter method, return iter of that raw data — creating a brand new iterator each time dunder iter is called. Never store the iterator as instance state. Each caller to dunder iter gets their own fresh, independent iterator starting from position zero. Multiple consumers can iterate simultaneously with no interference.

With this distinction clear, the industrial applications become obvious. Database cursors expose query results through the iteration protocol. When you write a for loop over a Django query result, you are not loading all rows into memory. You are calling dunder next on a database cursor, which fetches rows from the database one batch at a time. The consuming code uses a plain for loop and never needs to know whether it is iterating a list or querying a live database. Large file processing in data engineering relies on this protocol constantly. API pagination in network clients uses it to hide the complexity of HTTP requests, authentication, and page transitions behind a simple for loop interface. IoT sensor streams use it to read live measurements from hardware one value at a time.

The distinction between iterables and iterators is subtle but consequential. Iterables produce fresh iterators on demand and can be iterated multiple times. Iterators track state, exhaust after one pass, and return themselves from dunder iter. The for loop protocol calls dunder iter once and dunder next repeatedly. The silent bug occurs when returning self from an iterable's dunder iter method. The fix is to return iter of self dot data every time. In our next lecture, we will see how generators make implementing iterators dramatically simpler — instead of writing a full class with dunder iter and dunder next and manually managing a position counter, you write a function with a single yield keyword, and Python handles all the state management automatically. But now that you understand the protocol precisely, you will understand exactly what a generator is doing under the hood.
