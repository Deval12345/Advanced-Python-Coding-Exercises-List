# Key Points — Lecture 24: High-Level Concurrency APIs — Controlling Async at Scale

---

- **Unbounded async concurrency is as dangerous as no concurrency at all.** Spawning ten thousand coroutines simultaneously opens ten thousand network connections at once — external APIs respond with rate-limit errors, your own process exhausts its file descriptor limit, and the server crashes. The feature of async that makes it powerful (many concurrent operations) becomes a liability without an upper bound. Real systems have resource constraints at every layer: API rate limits, connection pool sizes, file descriptor limits. The high-level async APIs exist to encode those constraints directly into your code.

- **`asyncio.Semaphore(N)` limits the number of coroutines that can be inside a critical section simultaneously.** It works like a parking lot with N spaces: coroutines enter with `async with semaphore:`, which blocks if all N slots are occupied, and releases a slot when the block exits. This is the standard production pattern for any fan-out operation against a rate-limited external API. Setting `N = min(api_rate_limit, connection_pool_size)` directly maps the real-world constraint into your async code, preventing both server overload and client resource exhaustion.

- **`asyncio.wait(tasks, return_when=...)` provides fine-grained coordination that `asyncio.gather` cannot.** While `gather` waits for every task and cancels all on the first exception, `wait` returns control when a meaningful event occurs. `FIRST_COMPLETED` enables the race pattern — submit requests to multiple endpoints simultaneously, use the fastest response, cancel the rest. `FIRST_EXCEPTION` enables fail-fast error propagation. `ALL_COMPLETED` enables flexible gathering where you inspect individual task results and exceptions separately. `wait` returns two sets: `done` and `pending`.

- **After using `asyncio.wait` with `FIRST_COMPLETED`, always drain the cancelled pending tasks.** Cancel each task in the pending set, then `await asyncio.gather(*pending, return_exceptions=True)`. Without this drain, the event loop cannot deliver the cancellation to the tasks; they remain as dangling references and produce warnings on shutdown. This cleanup step is not optional — it is the correct resource management pattern for any race-style coordination.

- **`asyncio.wait_for(coroutine, timeout=seconds)` enforces a deadline on any coroutine.** Without timeouts, a coroutine waiting on a slow or hung external service waits indefinitely. In a busy server, many such hung coroutines grow the task queue, consume memory, and trigger a cascading failure where the service appears to slow down rather than crash — making the root cause difficult to diagnose. The production rule is simple and absolute: every external service call must have a timeout. When `TimeoutError` fires, the underlying coroutine is cancelled — its cleanup code in `finally` blocks still runs, ensuring resources are released.

- **The retry-with-timeout pattern is the foundation of resilient async service clients.** Wrap the external call in `asyncio.wait_for`, catch `asyncio.TimeoutError`, apply a brief sleep (optionally exponential backoff), and retry up to a maximum number of attempts. Each concurrent caller maintains its own independent retry state — a timeout in one coroutine has no effect on others running in the same `gather`. Python 3.11 added `asyncio.timeout` as a composable context manager, allowing timeout blocks to be applied to multiple statements rather than a single coroutine.

- **`asyncio.Queue` implements the async producer-consumer pattern with built-in backpressure.** `asyncio.gather` requires knowing all tasks upfront. Streaming workloads — Kafka consumers, WebSocket processors, web scrapers that discover new URLs dynamically — generate tasks over time. `asyncio.Queue(maxsize=N)` separates producers and consumers cleanly: producers `await queue.put()` (which blocks when the queue is full) and consumers `await queue.get()`. The `maxsize` parameter is the backpressure valve: when consumers are slower than the producer, the queue fills and the producer naturally slows down to match processing capacity.

- **The sentinel pattern provides clean shutdown for async queues with multiple consumers.** The producer puts `None` after all work items to signal shutdown. Each consumer, upon receiving `None`, re-puts it before breaking — ensuring every other consumer also receives the shutdown signal. This is the canonical shutdown mechanism because it is safe regardless of how many consumers are running and does not require any shared state or coordination beyond the queue itself.

- **`asyncio.Event` provides a one-shot binary signal that wakes all waiting coroutines simultaneously.** It starts unset; any number of coroutines can `await event.wait()` and they all pause at that line. When any coroutine calls `event.set()`, every pauser is immediately scheduled to resume. The event remains set permanently; future waiters continue without pausing. This is the correct tool for startup coordination (all workers wait for configuration to load), availability signals (a connection pool has a free connection), and initialization gates. It is edge-triggered — the wakeup is instant with no polling delay and no CPU waste between checks.
